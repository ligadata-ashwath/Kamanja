# zookeeper parameters
zookeeper.connect=172.30.2.172:2181
#zookeeper.session.timeout.ms=400
#zookeeper.sync.time.ms=200
 
# kafka parameters
kafka.group.id= archivejdbcsink
kafka.topic=cops_archive

# number of parallel kafka consumers to run
consumer.threads=1

# implementation class to process messages
adapter.message.processor=com.ligadata.adapters.container.FileStatusSink

# uri to create files under
#hdfs.uri=file:/tmp/data/instrumentationlog
hdfs.uri=hdfs://172.30.2.208:9000/bofA/outputAdapter/instrumentationlog

# prefix to name all files created under above uri
file.prefix=AppLog

# can be deflate, snappy, bzip2, xz
# if not given, no compression is used
file.compression=bzip2

# SimpleDateFormat format string used to parse date in input message
input.date.format=yyyy-MM-dd' 'HH:mm:ss

# partition messages using these comma separated ordered list of attributes
# format: attributename1,attributename2,..
# attribute names should match schema definition.
# optional SimpleDateFormat format string can be used after ":" for date attributes 
file.partition.strategy=timestamp:yyyy,timestamp:MM,timestamp:dd

# Avro schema file location
#schema.file=src/main/resources/InstrumentationLog.avsc
schema.file=./InstrumentationLog.avsc

# jdbc connection
jdbc.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
jdbc.url=jdbc:sqlserver://172.30.2.81:1433;databaseName=bofA;
jdbc.port=1433
jdbc.database=admin
jdbc.user=admin
jdbc.password=pass123
jdbc.insert.statement=INSERT INTO [dbo].[COPS_COMPLIANCE] ([FILE_ID],[FILE_NAME],[FILE_DATETIME],[EVENTS_COUNT])VALUES (?,?,?,?)


# parameters to control message batching
# messages will be written every "count" messages or every "interval" seconds
sync.messages.count=3
sync.interval.seconds=60
