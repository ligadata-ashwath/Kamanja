# zookeeper parameters
zookeeper.connect=127.0.0.1:2181
#zookeeper.session.timeout.ms=400
#zookeeper.sync.time.ms=200
 
# kafka parameters
kafka.group.id= copsjdbcsink
kafka.topic=cops_output

# These parameters will be passed to kafka consumer config.  
# offset storage can be kafka or zookeeper. default is zookeeper
#kafka.offsets.storage=kafka
# behavior if consumer offsets for above group.id are present. 
# can be smallest meaning read from beginning or largest meaning read only new messages
#kafka.auto.offset.reset=smallest

# number of parallel kafka consumers to run
consumer.threads=1

# implementation class to process messages
adapter.message.processor=com.ligadata.adapters.jdbc.BufferedJDBCSink

# SimpleDateFormat format string used to parse date in input message
input.date.format=yyyy-MM-dd'T'HH:mm:ss.SSS

# jdbc connection
jdbc.driver=com.microsoft.sqlserver.jdbc.SQLServerDriver
jdbc.url=jdbc:sqlserver://ec2-54-160-245-36.compute-1.amazonaws.com:1433;databaseName=admin;
jdbc.user=admin
jdbc.password=pass123
jdbc.insert.statement=INSERT INTO [COPS] ( [ACTIONCODE], [AIT], [APPLICATIONNAME], [AUTHENTICATIONMETHOD], [BUSINESSFUNCTION], [CLIENTIP], [CLIENTAPPNAME], [CONFIDENTIALDATALABELS], [CONFIDENTIALRECORDCOUNT], [CORRID], [CORRIDPARENT], [DATETIMESTAMP], [DEVICE], [ERRORMESSAGE], [EVENTSOURCE], [ID], [MESSAGETEXT], [PROPRIETARYDATALABELS], [PROPRIETARYDATAVALUES], [PROPRIETARYRECORDCOUNT], [PROCESSID], [PROCESSNAME], [RESOURCE], [RESOURCEHOST], [RESOURCEPORT], [RESOURCEPROTOCOL], [RESOURCETYPE], [RESULT], [TIMEZONE], [TYPECODE], [SYSTEMUSER], [USERID], [USERROLE], [AIT_NM], [COPS_ID], [DQ_SCORE], [EMP_FRST_NM], [EMP_LST_NM], [PERSON_ID], [SUM_NP], [SUM_PI], [CREATEDAT], [EXTRA]) VALUES ( {$details.action} {$ait}, {$details.application}, {$details.authenticationmethod}, {$details.businessfunction}, {$details.clientip}, {$details.clientappname}, {$details.confidentialdatalabels}, {$details.confidentialrecordcount}, {$corrId}, {$corrIdParent}, {$timestamp}, {$details.device}, {$details.errormessage}, {$details.eventsource}, {$Id}, {$details.message}, {$details.proprietarydatalabels}, {$details.proprietarydatavalues}, {$details.proprietaryrecordcount}, {$details.processid}, {$details.processname}, {$details.resource}, {$details.resourcehost}, {$details.resourceport}, {$details.resourceprotocol}, {$details.resourcetype}, {$details.result}, {$timezone}, {$details.type}, {$details.systemuser}, {$details.user}, {$details.userrole}, {$details.aitName}, {$details.copsId}, {$dqscore}, {$details.FirstName}, {$details.LastName}, {$details.personNumber}, {$details.sumNP}, {$details.sumPI}, {$createdAt}, {$_Remaining_Attributes_})

# parameters to control message batching
# messages will be written every "count" messages or every "interval" seconds
sync.messages.count=10
sync.interval.seconds=120
